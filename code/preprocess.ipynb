{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import os        \n",
    "import urllib.request\n",
    "import gzip\n",
    "import os.path\n",
    "import io\n",
    "from itertools import starmap\n",
    "from tdc.multi_pred import DDI\n",
    "from tdc.utils import get_label_map\n",
    "from tdc.resource import PrimeKG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Therapeutics Data Commons for DDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ddi_df = DDI(name = 'DrugBank').get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Drugs'] = pd.DataFrame({'Drug': ddi_df[['Drug1_ID', 'Drug1']].drop_duplicates().set_index('Drug1_ID').to_dict()['Drug1'] | ddi_df[['Drug2_ID', 'Drug2']].drop_duplicates().set_index('Drug2_ID').to_dict()['Drug2']}).rename_axis('Drug_ID')['Drug']\n",
    "data['DDI'] = ddi_df.set_index(['Drug1_ID', 'Drug2_ID'])[['Y']]\n",
    "data['DDI Labels'] = pd.Series(get_label_map(name = 'DrugBank', task = 'DDI')).rename_axis('Y').rename('Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DrugBank for SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download from https://go.drugbank.com/releases/5-1-10/downloads/all-drug-links\n",
    "zipfile.ZipFile('data/drugbank_all_drug_links.csv.zip').extractall('data')\n",
    "drugbank = pd.read_csv('data/drug links.csv', index_col=0)\n",
    "\n",
    "# download from https://go.drugbank.com/releases/5-1-10/downloads/all-structures\n",
    "zipfile.ZipFile('data/drugbank_all_structures.sdf.zip').extractall('data')\n",
    "with open('data/structures.sdf') as f:\n",
    "    col = None\n",
    "    for line in tqdm(f):\n",
    "        if line.startswith('> <'):\n",
    "            col = line[3:-2]\n",
    "        elif col:\n",
    "            if col == 'DATABASE_ID':\n",
    "                key = line[:-1]\n",
    "            else:\n",
    "                drugbank.loc[key, col] = line[:-1]\n",
    "            col = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11597"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugbank.to_csv('data/drugbank.csv')\n",
    "data['Drugs'] = pd.Series(data['Drugs'].to_dict() | drugbank['SMILES'].dropna().to_dict())\n",
    "data['Drugs'].name = 'Drug'\n",
    "data['Drugs'].index.name = 'Drug_ID'\n",
    "drugs = set(data['Drugs'].index)\n",
    "len(drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load HGNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNC = pd.read_csv('https://ftp.ebi.ac.uk/pub/databases/genenames/hgnc/tsv/hgnc_complete_set.txt', sep='\\t', low_memory=False)\n",
    "\n",
    "def get_map(from_: str, to: str) -> pd.Series:\n",
    "    return HGNC[[from_, to]].dropna().set_index(from_)[to]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneName_2_ccdID = get_map('entrez_id', 'ccds_id')\n",
    "geneName_2_ccdID.index = geneName_2_ccdID.index.astype(int)\n",
    "geneName_2_ccdID = geneName_2_ccdID.map(lambda x: x.split('|')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CCD for Protein Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCDS_protein_url = 'https://ftp.ncbi.nlm.nih.gov/pub/CCDS/current_human/CCDS_protein.current.faa.gz'\n",
    "                 # 'https://ftp.ncbi.nlm.nih.gov/pub/CCDS/current_human/CCDS_protein_exons.current.faa.gz'\n",
    "\n",
    "def fetch_faa(url):\n",
    "    return gzip.GzipFile(fileobj=io.BytesIO(urllib.request.urlopen(url).read()), mode='rb').read().decode('utf-8')\n",
    "\n",
    "CCDS_protein_raw = fetch_faa(CCDS_protein_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd_data = {}\n",
    "for line in CCDS_protein_raw.splitlines():\n",
    "    if line.startswith('>'):\n",
    "        ccd_data[ccd_id:=line[1:].strip().split('|')[0].split('.')[0]] = ''\n",
    "    else:\n",
    "        ccd_data[ccd_id] += line\n",
    "ccdID_2_ccdSeq = pd.Series(ccd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18929"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Proteins'] = geneID_2_ccdSeq = geneName_2_ccdID.map(ccdID_2_ccdSeq).rename_axis('Protein_ID').rename('Protein').dropna().sort_index()\n",
    "proteins = set(data['Proteins'].index)\n",
    "len(proteins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PrimeKG for PPI and DPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n"
     ]
    }
   ],
   "source": [
    "kg = PrimeKG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPI_df = kg.df.query('relation == \"protein_protein\"')[['x_id', 'y_id']].astype(int).set_index(['x_id', 'y_id']).rename_axis(['Protein1_ID', 'Protein2_ID'])\n",
    "data['PPI'] = kg.df.query('relation == \"protein_protein\"')[['x_id', 'y_id']].astype(int).rename({'x_id': 'Protein1_ID', 'y_id': 'Protein2_ID'}, axis=1)\n",
    "data['DPI'] = kg.df.query('x_type == \"drug\" and y_type == \"gene/protein\"')[['x_id', 'y_id']].astype(({'x_id': str, 'y_id': int})).rename({'x_id': 'Drug_ID', 'y_id': 'Protein_ID'}, axis=1)\n",
    "\n",
    "# filter out those interactions with protein that are not provided with CCD sequence\n",
    "data['PPI'] = data['PPI'][data['PPI'].isin(proteins).all(axis=1)].set_index(['Protein1_ID', 'Protein2_ID'])\n",
    "data['DPI'] = data['DPI'][data['DPI']['Protein_ID'].isin(proteins)]\n",
    "\n",
    "# filter out those interactions with drugs that are not provided with SMILES\n",
    "data['DPI'] = data['DPI'][data['DPI']['Drug_ID'].isin(drugs)].set_index(['Drug_ID', 'Protein_ID'])\n",
    "\n",
    "# drop the proteins that does not occur in any iteractions\n",
    "data['Proteins'] = data['Proteins'][sorted(set(data['DPI'].reset_index()['Protein_ID']) | set(data['PPI'].reset_index()['Protein1_ID']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DDI'].to_csv(\"../data/csv/DDI.csv\")\n",
    "data['PPI'].to_csv(\"../data/csv/PPI.csv\")\n",
    "data['DPI'].to_csv(\"../data/csv/DPI.csv\")\n",
    "data[\"Drugs\"].to_csv(\"../data/csv/Drugs.csv\")\n",
    "data[\"Proteins\"].to_csv(\"../data/csv/Proteins.csv\")\n",
    "data['DDI Labels'].to_csv('../data/csv/DDI Labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'DDI': pd.read_csv(\"../data/csv/DDI.csv\", index_col=(0,1)),\n",
    "    'DPI': pd.read_csv(\"../data/csv/DPI.csv\", index_col=(0,1)),\n",
    "    'PPI': pd.read_csv(\"../data/csv/PPI.csv\", index_col=(0,1)),\n",
    "    'Proteins': pd.read_csv(\"../data/csv/Proteins.csv\", index_col=0)['Protein'],\n",
    "    'Drugs': pd.read_csv(\"../data/csv/Drugs.csv\", index_col=0)['Drug'],\n",
    "    'DDI Labels': pd.read_csv('../data/csv/DDI Labels.csv', index_col=0)['Label']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepChem/ChemBERTa-77M-MLM were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'ESMTokenizer'. \n",
      "The class this function is called from is 'EsmTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/esm-1b were not used when initializing EsmModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'esm.embeddings.token_type_embeddings.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'esm.embeddings.LayerNorm.bias', 'lm_head.dense.weight', 'esm.embeddings.LayerNorm.weight']\n",
      "- This IS expected if you are initializing EsmModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm-1b and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, EsmTokenizer\n",
    "\n",
    "ChemBert = {\n",
    "    'tokenizer': AutoTokenizer.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\"),\n",
    "    'model': AutoModel.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\")\n",
    "} \n",
    "\n",
    "Esm1b = {\n",
    "    'tokenizer': EsmTokenizer.from_pretrained('facebook/esm-1b', do_lower_case=False),\n",
    "    'model': AutoModel.from_pretrained(\"facebook/esm-1b\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ChemBert['model'] = ChemBert['model'].to(device)\n",
    "Esm1b['model'] = Esm1b['model'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generator(tokenizer, model):\n",
    "    def get_features(text):\n",
    "        return model(**dict(starmap(lambda k, v: (k, v.to(device)), tokenizer(text, return_tensors='pt', max_length=512, padding=True, truncation=True).items()))).pooler_output[0].detach().cpu().numpy()\n",
    "    return get_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11597/11597 [00:55<00:00, 207.60it/s]\n"
     ]
    }
   ],
   "source": [
    "data['DrugFeatures'] = np.array(list(map(feature_generator(**ChemBert), tqdm(data['Drugs']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17258/17258 [01:28<00:00, 195.16it/s]\n"
     ]
    }
   ],
   "source": [
    "data['ProteinFeatures'] = np.array(list(map(feature_generator(**ChemBert), tqdm(data['Proteins']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/npy/DrugFeatures.npy\", data['DrugFeatures'])\n",
    "np.save(\"../data/npy/ProteinFeatures.npy\", data['ProteinFeatures'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "def calculate_similarity(smiles1, smiles2):\n",
    "    mol1 = Chem.MolFromSmiles(smiles1)\n",
    "    mol2 = Chem.MolFromSmiles(smiles2)\n",
    "\n",
    "    try:\n",
    "        fp1 = AllChem.GetMorganFingerprintAsBitVect(mol1, 2, nBits=2048)\n",
    "        fp2 = AllChem.GetMorganFingerprintAsBitVect(mol2, 2, nBits=2048)\n",
    "    except:\n",
    "        print(smiles1, smiles2)\n",
    "        return np.nan\n",
    "    similarity = DataStructs.TanimotoSimilarity(fp1, fp2)\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(row):\n",
    "    try:\n",
    "        return calculate_similarity(\n",
    "            data['Drugs']['Drug'][row['Drug1_ID']], \n",
    "            data['Drugs']['Drug'][row['Drug2_ID']]\n",
    "        )\n",
    "    except:\n",
    "        print(row['Drug1_ID'], row['Drug2_ID'])\n",
    "data['DDI']['Similarity'] = data['DDI'].apply(get_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(data, open('../dataset.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p1, p2 in data['PPI'].index:\n",
    "    assert (p2, p1) in data['PPI'].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'DDI': pd.read_csv(\"../data/csv/DDI.csv\", index_col=(0,1)),\n",
    "    'DPI': pd.read_csv(\"../data/csv/DPI.csv\", index_col=(0,1)),\n",
    "    'PPI': pd.read_csv(\"../data/csv/PPI.csv\", index_col=(0,1)),\n",
    "    'Proteins': pd.read_csv(\"../data/csv/Proteins.csv\", index_col=0)['Protein'],\n",
    "    'Drugs': pd.read_csv(\"../data/csv/Drugs.csv\", index_col=0)['Drug'],\n",
    "    'DDI Labels': pd.read_csv('../data/csv/DDI Labels.csv', index_col=0)['Label'],\n",
    "    'DrugFeatures': np.load(\"../data/npy/DrugFeatures.npy\"),\n",
    "    'ProteinFeatures': np.load(\"../data/npy/ProteinFeatures.npy\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pkl.load(open('../dataset.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DDI', 'DPI', 'PPI', 'Proteins', 'Drugs', 'DDI Labels', 'DrugFeatures', 'ProteinFeatures'])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
