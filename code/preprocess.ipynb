{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 11213/17261 [12:12<07:47, 12.94it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import pickle as pkl\n",
    "import jsonlines as jsonl\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline, EsmModel, EsmConfig, EsmTokenizer\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import os        \n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "import os.path\n",
    "import io                     \n",
    "from collections import defaultdict     \n",
    "from itertools import starmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load HGNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNC = pd.read_csv('https://ftp.ebi.ac.uk/pub/databases/genenames/hgnc/tsv/hgnc_complete_set.txt', sep='\\t', low_memory=False)\n",
    "\n",
    "def get_map(from_: str, to: str) -> pd.Series:\n",
    "    return HGNC[[from_, to]].dropna().set_index(from_)[to]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneName_2_ccdID = get_map('entrez_id', 'ccds_id')\n",
    "geneName_2_ccdID.index = geneName_2_ccdID.index.astype(int)\n",
    "geneName_2_ccdID = geneName_2_ccdID.map(lambda x: x.split('|')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CCD for Protein Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCDS_protein_url = 'https://ftp.ncbi.nlm.nih.gov/pub/CCDS/current_human/CCDS_protein.current.faa.gz'\n",
    "                 # 'https://ftp.ncbi.nlm.nih.gov/pub/CCDS/current_human/CCDS_protein_exons.current.faa.gz'\n",
    "\n",
    "def fetch_faa(url):\n",
    "    return gzip.GzipFile(fileobj=io.BytesIO(urllib.request.urlopen(url).read()), mode='rb').read().decode('utf-8')\n",
    "\n",
    "CCDS_protein_raw = fetch_faa(CCDS_protein_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd_data = {}\n",
    "for line in CCDS_protein_raw.splitlines():\n",
    "    if line.startswith('>'):\n",
    "        ccd_data[ccd_id:=line[1:].strip().split('|')[0].split('.')[0]] = ''\n",
    "    else:\n",
    "        ccd_data[ccd_id] += line\n",
    "ccdID_2_ccdSeq = pd.Series(ccd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Proteins'] = geneID_2_ccdSeq = geneName_2_ccdID.map(ccdID_2_ccdSeq).rename_axis('Protein_ID').rename('Protein').dropna()\n",
    "proteins = set(data['Proteins'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PrimeKG for PPI and DPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n"
     ]
    }
   ],
   "source": [
    "from tdc.resource import PrimeKG\n",
    "kg = PrimeKG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPI_df = kg.df.query('relation == \"protein_protein\"')[['x_id', 'y_id']].astype(int).set_index(['x_id', 'y_id']).rename_axis(['Protein1_ID', 'Protein2_ID'])\n",
    "data['PPI'] = kg.df.query('relation == \"protein_protein\"')[['x_id', 'y_id']].astype(int).rename({'x_id': 'Protein1_ID', 'y_id': 'Protein2_ID'}, axis=1)\n",
    "data['DPI'] = kg.df.query('x_type == \"drug\" and y_type == \"gene/protein\"')[['x_id', 'y_id']].astype(({'x_id': str, 'y_id': int})).rename({'x_id': 'Drug_ID', 'y_id': 'Protein_ID'}, axis=1)\n",
    "\n",
    "# filter out those iteractions with protein that are not provided with CCD sequence\n",
    "data['PPI'] = data['PPI'][data['PPI'].isin(proteins).all(axis=1)].set_index(['Protein1_ID', 'Protein2_ID'])\n",
    "data['DPI'] = data['DPI'][data['DPI']['Protein_ID'].isin(proteins)].set_index(['Drug_ID', 'Protein_ID'])\n",
    "\n",
    "# drop the proteins that does not occur in any iteractions\n",
    "data['Proteins'] = data['Proteins'][sorted(set(data['DPI'].reset_index()['Protein_ID']) | set(data['PPI'].reset_index()['Protein1_ID']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "display_relation\n",
       "target         16380\n",
       "enzyme          5317\n",
       "transporter     3092\n",
       "carrier          864\n",
       "dtype: int64"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.df.query('x_type == \"drug\" and y_type == \"gene/protein\"').value_counts('display_relation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Therapeutics Data Commons for DDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from tdc.multi_pred import DDI\n",
    "from tdc.utils import get_label_map\n",
    "ddi_df = DDI(name = 'DrugBank').get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Drugs'] = pd.DataFrame({'Drug': ddi_df[['Drug1_ID', 'Drug1']].drop_duplicates().set_index('Drug1_ID').to_dict()['Drug1'] | ddi_df[['Drug2_ID', 'Drug2']].drop_duplicates().set_index('Drug2_ID').to_dict()['Drug2']}).rename_axis('Drug_ID')['Drug']\n",
    "data['DDI'] = ddi_df.set_index(['Drug1_ID', 'Drug2_ID'])[['Y']]\n",
    "data['DDI Labels'] = pd.Series(get_label_map(name = 'DrugBank', task = 'DDI')).rename_axis('Y').rename('Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DDI'].to_csv(\"../data/csv/DDI.csv\")\n",
    "data['PPI'].to_csv(\"../data/csv/PPI.csv\")\n",
    "data['DPI'].to_csv(\"../data/csv/DPI.csv\")\n",
    "data[\"Drugs\"].to_csv(\"../data/csv/Drugs.csv\")\n",
    "data[\"Proteins\"].to_csv(\"../data/csv/Proteins.csv\")\n",
    "data['DDI Labels'].to_csv('../data/csv/DDI Labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'DDI': pd.read_csv(\"../data/csv/DDI.csv\", index_col=(0,1)),\n",
    "    'DPI': pd.read_csv(\"../data/csv/DPI.csv\", index_col=(0,1)),\n",
    "    'PPI': pd.read_csv(\"../data/csv/PPI.csv\", index_col=(0,1)),\n",
    "    'Proteins': pd.read_csv(\"../data/csv/Proteins.csv\", index_col=0)['Protein'],\n",
    "    'Drugs': pd.read_csv(\"../data/csv/Drugs.csv\", index_col=0)['Drug'],\n",
    "    'DDI Labels': pd.read_csv('../data/csv/DDI Labels.csv', index_col=0)['Label']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepChem/ChemBERTa-77M-MLM were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'ESMTokenizer'. \n",
      "The class this function is called from is 'EsmTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/esm-1b were not used when initializing EsmModel: ['lm_head.layer_norm.bias', 'esm.embeddings.token_type_embeddings.weight', 'esm.embeddings.LayerNorm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'esm.embeddings.LayerNorm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing EsmModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm-1b and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ChemBert = {\n",
    "    'tokenizer': AutoTokenizer.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\"),\n",
    "    'model': AutoModel.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\")\n",
    "} \n",
    "\n",
    "Esm1b = {\n",
    "    'tokenizer': EsmTokenizer.from_pretrained('facebook/esm-1b', do_lower_case=False),\n",
    "    'model': AutoModel.from_pretrained(\"facebook/esm-1b\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ChemBert['model'] = ChemBert['model'].to(device)\n",
    "Esm1b['model'] = Esm1b['model'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generator(tokenizer, model):\n",
    "    def get_features(text):\n",
    "        return model(**dict(starmap(lambda k, v: (k, v.to(device)), tokenizer(text, return_tensors='pt', max_length=512, padding=True, truncation=True).items()))).pooler_output[0].detach().cpu().numpy()\n",
    "    return get_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1706/1706 [00:08<00:00, 206.47it/s]\n"
     ]
    }
   ],
   "source": [
    "data['DrugFeatures'] = np.array(list(map(feature_generator(**ChemBert), tqdm(data['Drugs']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17260/17260 [01:30<00:00, 190.15it/s]\n"
     ]
    }
   ],
   "source": [
    "data['ProteinFeatures'] = np.array(list(map(feature_generator(**ChemBert), tqdm(data['Proteins']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/npy/DrugFeatures.npy\", data['DrugFeatures'])\n",
    "np.save(\"../data/npy/ProteinFeatures.npy\", data['ProteinFeatures'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "def calculate_similarity(smiles1, smiles2):\n",
    "    mol1 = Chem.MolFromSmiles(smiles1)\n",
    "    mol2 = Chem.MolFromSmiles(smiles2)\n",
    "\n",
    "    try:\n",
    "        fp1 = AllChem.GetMorganFingerprintAsBitVect(mol1, 2, nBits=2048)\n",
    "        fp2 = AllChem.GetMorganFingerprintAsBitVect(mol2, 2, nBits=2048)\n",
    "    except:\n",
    "        print(smiles1, smiles2)\n",
    "        return np.nan\n",
    "    similarity = DataStructs.TanimotoSimilarity(fp1, fp2)\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DDI'].set_index(['Drug1_ID', 'Drug2_ID']).to_pickle(\"../data/pkl/DDI.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(row):\n",
    "    try:\n",
    "        return calculate_similarity(\n",
    "            data['Drugs']['Drug'][row['Drug1_ID']], \n",
    "            data['Drugs']['Drug'][row['Drug2_ID']]\n",
    "        )\n",
    "    except:\n",
    "        print(row['Drug1_ID'], row['Drug2_ID'])\n",
    "data['DDI']['Similarity'] = data['DDI'].apply(get_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(data, open('../dataset.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'DDI': pd.read_csv(\"../data/csv/DDI.csv\", index_col=(0,1)),\n",
    "    'DPI': pd.read_csv(\"../data/csv/DPI.csv\", index_col=(0,1)),\n",
    "    'PPI': pd.read_csv(\"../data/csv/PPI.csv\", index_col=(0,1)),\n",
    "    'Proteins': pd.read_csv(\"../data/csv/Proteins.csv\", index_col=0)['Protein'],\n",
    "    'Drugs': pd.read_csv(\"../data/csv/Drugs.csv\", index_col=0)['Drug'],\n",
    "    'DDI Labels': pd.read_csv('../data/csv/DDI Labels.csv', index_col=0)['Label'],\n",
    "    'DrugFeatures': np.load(\"../data/npy/DrugFeatures.npy\"),\n",
    "    'ProteinFeatures': np.load(\"../data/npy/ProteinFeatures.npy\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pkl.load(open('../dataset.pkl', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
